# Generative Machine Learning

[Illustrated Stable Diffusion](https://jalammar.github.io/illustrated-stable-diffusion/) & [How diffusion models work](https://twitter.com/iScienceLuvr/status/1592860019057250304) are [great reads](https://news.ycombinator.com/item?id=33084205).

Progress in models like [Midjourney](https://www.midjourney.com/) is getting [insanely good](https://www.reddit.com/r/midjourney/comments/yyom8a/london_1910/). Can even generate [nice header images](https://twitter.com/euboid/status/1593174650262986754) or [logos](https://twitter.com/sindresorhus/status/1590640203781533696).

## Notes

- [The net effect of the last 18 mo has been to slightly lubricate human imagination, making it easier for individuals to visualize possible worlds/scenes/moods. It’s only a medium-big deal—unless this is a foretaste of similar acceleration in music, code, and text.](https://twitter.com/Ted_Underwood/status/1566787680872157185)
- [Greatest impact of "generative ML" will not be on art/creation, but by bringing technology leverage to billions of hours of boring data entry/manipulation jobs.](https://twitter.com/WillManidis/status/1584900092615528448)
- [Diffusion is just an easy-to-optimize way to give neural networks adaptive computation time. Makes sense then that diffusion models beat GANs, which only get one forward pass to generate an image. Have to wonder what other ways there are to integrate for loops into NNs.](https://twitter.com/jxmnop/status/1586000934248792065)

## Links

- [DALL·E: Introducing Outpainting (2022)](https://openai.com/blog/dall-e-introducing-outpainting/) ([HN](https://news.ycombinator.com/item?id=32664507))
- [Ask HN: Am I the only one tired of seeing DALL·E /Stable Diffusion posts? (2022)](https://news.ycombinator.com/item?id=32665587)
- [Stable Diffusion is a big deal (2022)](https://simonwillison.net/2022/Aug/29/stable-diffusion/) ([HN](https://news.ycombinator.com/item?id=32634074))
- [Stable Diffusion Textual Inversion](https://github.com/hlky/sd-enable-textual-inversion) ([HN](https://news.ycombinator.com/item?id=32643564))
- [Stable Diffusion Public Release (2022)](https://stability.ai/blog/stable-diffusion-public-release) ([HN](https://news.ycombinator.com/item?id=32555028))
- [Peacasso](https://github.com/victordibia/peacasso) - Web UI for Stable Diffusion Models. ([Reddit](https://www.reddit.com/r/MachineLearning/comments/x5w9py/p_peacasso_a_web_ui_for_stable_diffusion_models/))
- [Optimized Stable Diffusion](https://github.com/basujindal/stable-diffusion) - Modified version of the Stable Diffusion repo, optimized to use less VRAM than the original by sacrificing inference speed.
- [EvoGen](https://github.com/MagnusPetersen/EvoGen-Prompt-Evolution) - Evolutionary algorithm that optimizes prompts for text-to-image models for aesthetics.
- [All about the fundamentals and working of Diffusion Models](https://github.com/AakashKumarNain/diffusion_models)
- [Experiments with Stable Diffusion](https://github.com/justinpinkney/stable-diffusion) ([Tweet](https://twitter.com/Buntworthy/status/1566744186153484288))
- [DreamStudio](https://beta.dreamstudio.ai/dream) - Front end and API to use the recently released stable diffusion image generation model.
- [Stable Diffusion web UI](https://github.com/AUTOMATIC1111/stable-diffusion-webui) ([HN](https://news.ycombinator.com/item?id=32784181))
- [koi](https://github.com/nousr/koi) - Open source plug-in for Krita that allows you to use AI to accelerate your art workflow.
- [Awesome Stable-Diffusion](https://github.com/awesome-stable-diffusion/awesome-stable-diffusion)
- [Simple Stable Diffusion](https://github.com/hackclub/simple-stable-diffusion) - Get stable diffusion running in <10 minutes in colab.
- [Stable Diffusion Playground](https://github.com/gordicaleksa/stable_diffusion_playground)
- [Create videos with Stable Diffusion](https://github.com/nateraw/stable-diffusion-videos) - By exploring the latent space and morphing between text prompts.
- [Long Stable Diffusion: Long-form text to images](https://github.com/sharonzhou/long_stable_diffusion)
- [Infinite Stable Diffusion Videos](https://orbdog.com/) ([HN](https://news.ycombinator.com/item?id=32720924))
- [Why 'weird patterns' arise in the latent space of an image generation models](https://twitter.com/mattskala/status/1567300206969982979) ([Tweet](https://twitter.com/ai_curio/status/1567253704872427520))
- [Textual Inversion fine-tuning example](https://github.com/huggingface/diffusers/tree/main/examples/textual_inversion) ([Tweet](https://twitter.com/psuraj28/status/1567212122970685442))
- [Progressive Distillation for Fast Sampling of Diffusion Models (2022)](https://arxiv.org/abs/2202.00512)
- [Stable Diffusion prompting cheat sheet](https://moritz.pm/posts/parameters)
- [The Man behind Stable Diffusion (2022)](https://www.youtube.com/watch?v=YQ2QtKcK2dA)
- [Inpainting](https://inpainter.vercel.app/) - Web GUI for inpainting with Stable Diffusion using the Replicate API. ([Code](https://github.com/zeke/inpainter))
- [Dreambooth on Stable Diffusion](https://github.com/XavierXiao/Dreambooth-Stable-Diffusion) ([Optimized Fork](https://github.com/gammagec/Dreambooth-SD-optimized))
- [Japanese Stable Diffusion](https://github.com/rinnakk/japanese-stable-diffusion)
- [Stable Diffusion web UI](https://github.com/sd-webui/stable-diffusion-webui)
- [Stable DreamBooth](https://github.com/Victarry/stable-dreambooth) - Implementation of DreamBooth based on Stable Diffusion.
- [George Hotz | stable diffusion, in tinygrad (2022)](https://www.youtube.com/watch?v=4V9VHt_YwFQ)
- [CLIP-Mesh: Generating textured meshes from text using pretrained image-text models (2022)](https://www.nasir.lol/clipmesh) ([Code](https://github.com/NasirKhalid24/CLIP-Mesh))
- [Prompt-to-Prompt Image Editing with Cross Attention Control (2022)](https://arxiv.org/abs/2208.01626) ([Code](https://github.com/bloc97/CrossAttentionControl))
- [Stable Diffusion REST API](https://github.com/yuanqing/stable-diffusion-rest-api)
- [Visual Taste Approximator](https://github.com/SelfishGene/visual_taste_approximator) - Simple tool that helps anyone create an automatic replica of themselves that can approximate their own personal visual taste.
- [Stable Diffusion concepts library](https://huggingface.co/sd-concepts-library) ([Tweet](https://twitter.com/karpathy/status/1568644275247923206))
- [Stable Diffusion for Apple Silicon](https://github.com/FahimF/sd-gui)
- [Learn time series with a story illustrated by Stable Diffusion (2022)](https://tigyog.app/d/L-8D8R2yeXLY/r/an-everyday-look-at-time-series) ([HN](https://news.ycombinator.com/item?id=32768005))
- [Daemon which watches a queue and runs stable diffusion](https://github.com/w4ffl35/stablediffusiond)
- [Text-to-image for my inbox (2022)](https://www.kmjn.org/notes/txt2img_email_visualization.html)
- [sdutils](https://github.com/newsbubbles/sdutils) - Stable Diffusion Utility Wrapper.
- [Diffusion Bee](https://github.com/divamgupta/diffusionbee-stable-diffusion-ui) - Stable Diffusion GUI App for M1 Mac. ([HN](https://news.ycombinator.com/item?id=32804695))
- [Art Hub AI](https://arthub.ai/) - Discover, upload and share AI generated art pieces..
- [AI Content Generation, Part 1: Machine Learning Basics](https://www.jonstokes.com/p/ai-content-generation-part-1-machine) ([Tweet](https://twitter.com/jonst0kes/status/1569400246714908672))
- [Inpainting with Stable Diffusion & Replicate](https://inpainter.vercel.app/)
- [Diffusion Models: A Comprehensive Survey of Methods and Applications](https://github.com/YangLing0818/Diffusion-Models-Papers-Survey-Taxonomy)
- [stability-clients](https://github.com/Stability-AI/stability-sdk) - Client implementations that interact with the Stability Generator API.
- [Storyweaving with AI](https://webaverse.ghost.io/storyweaving-with-ai/) ([Code](https://github.com/webaverse/lore-engine))
- [dreamlike.art](https://dreamlike.art/) - AI Art Generator.
- [Stable Diffusion Photoshop Plugin](https://christiancantrell.com/#ai-ml)
- [Outpainting with Stable Diffusion on an infinite canvas](https://github.com/lkwq007/stablediffusion-infinity)
- [Stable Diffusion: With Composition](https://github.com/Slickytail/stable-diffusion-compositional)
- [Swift Diffusion](https://github.com/liuliu/swift-diffusion) - Single-file re-implementation of Stable Diffusion model.
- [From Deep Learning Foundations to Stable Diffusion (2022)](https://www.fast.ai/posts/part2-2022.html) ([HN](https://news.ycombinator.com/item?id=32864783))
- [Production software using OpenAI GPT-3 APIs](https://twitter.com/simonw/status/1570820425877434368)
- [CHARL-E](https://github.com/cbh123/charl-e) - Run Stable Diffusion on your M1 Mac. ([HN](https://news.ycombinator.com/item?id=32878626))
- [Stable Diffusion in Tensorflow / Keras](https://github.com/divamgupta/stable-diffusion-tensorflow) ([Colab](https://colab.research.google.com/drive/1fBlfPsL5DEscub0O_3oJNnJbON4w3EKq?usp=sharing))
- [Osmosis.Studio](http://osmosis.studio/) - Product Ad Creative and Optimization with Generative AI.
- [Upscale to huge sizes and add detail with SD Upscale, it's easy!](https://www.reddit.com/r/StableDiffusion/comments/xkjjf9/upscale_to_huge_sizes_and_add_detail_with_sd/)
- [Open Prompts](https://github.com/krea-ai/open-prompts) - Dataset of 10M Stable Diffusion generations. ([HN](https://news.ycombinator.com/item?id=32943224))
- [KREA](https://www.krea.ai/) - Create better prompts.
- [GLID-3-XL-stable](https://github.com/Jack000/glid-3-xl-stable) - Stable diffusion back-ported to the OpenAI guided diffusion codebase, for easier development and training.
- [ImaginAIry](https://github.com/brycedrennan/imaginAIry) - AI imagined images. Pythonic generation of stable diffusion images.
- [UnstableFusion](https://github.com/ahrm/UnstableFusion) - Stable Diffusion desktop frontend with inpainting, img2img and more.
- [Dreamfields-3D](https://github.com/shengyu-meng/dreamfields-3D) - Colab friendly toolkit to generate 3D mesh model / video / nerf instance / multiview images of colourful 3D objects by text and image prompts input, based on dreamfields.
- [fast-stable-diffusion colabs](https://github.com/TheLastBen/fast-stable-diffusion) - 25% speed increase + memory efficient. ([Colab](https://colab.research.google.com/github/TheLastBen/fast-stable-diffusion/blob/main/fast_stable_diffusion_AUTOMATIC1111.ipynb))
- [High-performance image generation using Stable Diffusion in KerasCV](https://keras.io/guides/keras_cv/generate_images_with_stable_diffusion/) ([HN](https://news.ycombinator.com/item?id=33005585))
- [Video Killed The Radio Star](https://github.com/dmarx/video-killed-the-radio-star) - Notebook and tools for end-to-end automation of music video production with generative AI.
- [Custom scripts for the stable diffusion web UI](https://github.com/Pfaeff/sd-web-ui-scripts)
- [Phenaki](https://phenaki.video/) - Model for generating minutes-long, changing-prompt videos from text. ([HN](https://news.ycombinator.com/item?id=33025189))
- [GhostlyStock](https://www.ghostlystock.com/) - Stock Photos Using Stable Diffusion. ([HN](https://news.ycombinator.com/item?id=33038117))
- [Prompt engineering is hard (2022)](https://xeiaso.net/blog/prompt-engineering)
- [Notes and plans for Fast Diffusion course](https://github.com/fastai/fastdiffusion)
- [Stable Diffusion CPU only](https://github.com/darkhemic/stable-diffusion-cpuonly)
- [TabDDPM: Modelling Tabular Data with Diffusion Models (2022)](https://arxiv.org/abs/2209.15421) ([Code](https://github.com/rotot0/tab-ddpm))
- [Animation Script](https://github.com/Animator-Anon/Animator) - Animator script for SD Web UI.
- [Latent space walking: minimal Keras Colab](https://colab.research.google.com/drive/1C2UhtHvHYzkdidFd_CfZTimuwJ0oH3SA?usp=sharing) ([Tweet](https://twitter.com/fchollet/status/1577069074802421760))
- [The Illustrated Stable Diffusion (2022)](https://jalammar.github.io/illustrated-stable-diffusion/) ([HN](https://news.ycombinator.com/item?id=33084205))
- [DALL·E Node](https://github.com/ezzcodeezzlife/dalle-node) - Use DALL·E 2 with NodeJS.
- [Novel View Synthesis with Diffusion Models (2022)](https://3d-diffusion.github.io/) ([HN](https://news.ycombinator.com/item?id=33085837))
- [Imagen Video](https://imagen.research.google/video/) - High definition video generation with diffusion models. ([HN](https://news.ycombinator.com/item?id=33098704))
- [Is the AI spell-casting metaphor harmful or helpful? (2022)](https://simonwillison.net/2022/Oct/5/spell-casting/)
- [Ask HN: What am I supposed to do after I’m “disrupted”? Work in video and CG (2022)](https://news.ycombinator.com/item?id=33099182)
- [Stable-Dreamfusion](https://github.com/ashawkey/stable-dreamfusion) - PyTorch implementation of the text-to-3D model Dreamfusion, powered by the Stable Diffusion text-to-2D model. ([HN](https://news.ycombinator.com/item?id=33109243))
- [Text2All](https://github.com/AvrahamRaviv/Text2All) - Comprehensive list of resources about text-guided generative models.
- [HuggingFace Space and model of VToonify (2022)](https://colab.research.google.com/github/williamyang1991/VToonify/blob/master/notebooks/inference_playground.ipynb) ([Tweet](https://twitter.com/ShuaiYang1991/status/1576937439528042499))
- [How AI Image Generators Work (Stable Diffusion / Dall-E) (2022)](https://www.youtube.com/watch?v=1CIpzeNxIhU)
- [Manifest](https://github.com/HazyResearch/manifest) - How to make prompt programming with Foundation Models a little easier.
- [Implementation of Dreambooth by way of Textual Inversion](https://github.com/JoePenna/Dreambooth-Stable-Diffusion)
- [InvokeAI](https://github.com/invoke-ai/InvokeAI) - Open source Stable Diffusion toolkit and WebUI. ([HN](https://news.ycombinator.com/item?id=33155074))
- [Astraea](https://www.strmr.com/) - Tailor-made AI image generation.
- [Getting started with diffusion](https://github.com/fastai/diffusion-nbs)
- [14 awesome Stable Diffusion notebooks](https://twitter.com/StableDiffusion/status/1580840619114582016)
- [Understanding Diffusion Models: A Unified Perspective (2022)](https://arxiv.org/abs/2208.11970) ([Annotated](https://github.com/AakashKumarNain/annotated_research_papers/blob/master/diffusion_models/understanding_diffusion_models.pdf))
- [Maple Diffusion](https://github.com/madebyollin/maple-diffusion) - Runs Stable Diffusion models locally on macOS / iOS devices, in Swift, using the MPSGraph framework.
- [Asymmetric Tiling for stable-diffusion-webui](https://github.com/tjm35/asymmetric-tiling-sd-webui)
- [Prompt-to-Prompt: Latent Diffusion and Stable Diffusion implementation (2022)](https://github.com/google/prompt-to-prompt)
- [Real-time inference for Stable Diffusion](https://github.com/stochasticai/x-stable-diffusion)
- [latentspace.dev](https://www.latentspace.dev/) - Exploring stable diffusion latent space. ([Tweet](https://twitter.com/QasimMunye/status/1581784155528232960))
- [Photoshop for Text (2022)](https://stephanango.com/photoshop-for-text) ([HN](https://news.ycombinator.com/item?id=33253606))
- [Artists: AI Image Generators Can Make Copycat Images in Seconds (2022)](https://www.businessinsider.com/ai-image-generators-artists-copying-style-thousands-images-2022-10)
- [Stability.AI Easy Diffusion](https://github.com/WASasquatch/easydiffusion) - Google Colab Notebook designed to be a relatively easy to use all-in-one suite for stable diffusion.
- [Why we chose not to release Stable Diffusion 1.5 as quickly (2022)](https://danieljeffries.substack.com/p/why-the-future-of-open-source-ai) ([HN](https://news.ycombinator.com/item?id=33283712))
- [A Survey on Generative Diffusion Model (2022)](https://arxiv.org/abs/2209.02646) ([Code](https://github.com/chq1155/A-Survey-on-Generative-Diffusion-Model))
- [Making a Video from Prompts with Stable Diffusion](https://github.com/johnrobinsn/diffusion_experiments)
- [Maple Diffusion](https://github.com/mortenjust/maple-diffusion) - Stable Diffusion inference on iOS / macOS using MPSGraph.
- [VectorArt.ai](https://vectorart.ai/) - Vector Graphics with Stable Diffusion. ([HN](https://news.ycombinator.com/item?id=33308248))
- [Generative Image workflow in Runway](https://twitter.com/notiansans/status/1583528842898984961)
- [How does stable diffusion work](https://twitter.com/danqing_liu/status/1584611896682246145)
- [DiffusionDB](https://github.com/poloclub/diffusiondb) - Large-scale text-to-image prompt gallery dataset based on Stable Diffusion.
- [Implementation of a server for the Stability AI Stable Diffusion API](https://github.com/hafriedlander/stable-diffusion-grpcserver)
- [Compositional Visual Generation with Composable Diffusion Models (2022)](https://arxiv.org/abs/2206.01714) ([Code](https://github.com/energy-based-model/Compositional-Visual-Generation-with-Composable-Diffusion-Models-PyTorch))
- [Avatar AI](https://avatarai.me/) - Create your own AI-generated avatars.
- [CLIP Interrogator](https://huggingface.co/spaces/pharma/CLIP-Interrogator)
- [Animation focused workflow frontend for Stable Diffusion](https://github.com/amotile/stable-diffusion-studio)
- [Backend for my Stable diffusion projects](https://github.com/amotile/stable-diffusion-backend)
- [Carefree Creator](https://github.com/carefree0910/carefree-creator) - AI-powered creator for everyone.
- [Categorical SDEs with Simplex Diffusion (2022)](https://arxiv.org/abs/2210.14784) ([Tweet](https://twitter.com/TheOneKloud/status/1586719623482834945))
- [Reaction-diffusion](https://github.com/jasonwebb/reaction-diffusion-playground) - Mathematical model describing how two chemicals might react to each other as they diffuse through a medium together.
- [Banana Serverless](https://github.com/bananaml/serverless-template-stable-diffusion) - Basic framework for serving Stable Diffusion in production using simple HTTP servers.
- [Sketch Diffusion – Live Painting with Stable Diffusion on Meta Quest Pro](https://www.t-da.io/labs)
- [List of Stable Diffusion resources](https://rentry.co/sdupdates) ([HN](https://news.ycombinator.com/item?id=33416632))
- [Invasive Diffusion: one unwilling illustrator found her turned into an AI model (2022)](https://waxy.org/2022/11/invasive-diffusion-how-one-unwilling-illustrator-found-herself-turned-into-an-ai-model/) ([HN](https://news.ycombinator.com/item?id=33422990))
- [AI Horde](https://github.com/db0/AI-Horde) - Crowdsourced distributed cluster for AI art and text generation.
- [Distributed Diffusion](https://github.com/chavinlo/distributed-diffusion) - Train a Stable Diffusion model over the internet with Hivemind.
- [Unprompted for Stable Diffusion](https://github.com/ThereforeGames/unprompted) - Text generator written for Stable Diffusion workflows.
- [Rise of generative AI will be comparable to the rise of CGI in the early 90s (2022)](https://sarharibhakti.substack.com/p/rise-of-generative-ai-will-be-comparable) ([HN](https://news.ycombinator.com/item?id=33429608))
- [DPM-Solver: A Fast ODE Solver for Diffusion Probabilistic Model Sampling in Around 10 Steps (2022)](https://arxiv.org/abs/2206.00927) ([Code](https://github.com/LuChengTHU/dpm-solver))
- [Ask CLI](https://github.com/sw-yx/ask-cli) - Deno CLI for pinging GPT-3 and iterating with chain of thought prompting.
- [Hugging Face Diffusion Models Course](https://github.com/huggingface/diffusion-models-class)
- [Ask HN: How to get into AI generation (images,text) (2022)](https://news.ycombinator.com/item?id=33479367)
- [Stable Diffusion and AI generated art is absolutely wild in every way (2022)](https://a.wholelottanothing.org/2022/11/02/stable-diffusion-and-ai-generated-art-is-absolutely-wild-in-every-way/)
- [diffusers-rs](https://github.com/LaurentMazare/diffusers-rs) - Diffusers API in Rust/Torch.
- [AI Art Tools and Resources in One Place](https://www.aiartapps.com/) ([HN](https://news.ycombinator.com/item?id=33501670))
- [Stretch iPhone to its limit: 2GiB Stable Diffusion model runs locally on device (2022)](https://liuliu.me/eyes/stretch-iphone-to-its-limit-a-2gib-model-that-can-draw-everything-in-your-pocket/) ([HN](https://news.ycombinator.com/item?id=33539192))
- [Generative AI: A Creative New World (2022)](https://www.sequoiacap.com/article/generative-ai-a-creative-new-world/)
- [Stable Diffusion with Colossal-AI](https://github.com/hpcaitech/ColossalAI/tree/main/examples/images/diffusion)
- [DiffuSeq: Sequence to Sequence Text Generation with Diffusion Models (2022)](https://arxiv.org/abs/2210.08933) ([Code](https://github.com/Shark-NLP/DiffuSeq))
- [Stable-Diffusion + Fused CUDA kernels](https://github.com/tfernd/sd-fused)
- [Dall-E 2 AI Image Generator](https://dalle-2.vercel.app/) - Using Upstash for message queue + Redis. ([Code](https://github.com/domeccleston/dalle-2))
- [Versatile Diffusion: Text, Images and Variations All in One Diffusion Model (2022)](https://arxiv.org/abs/2211.08332) ([Code](https://github.com/SHI-Labs/Versatile-Diffusion))
- [How diffusion models work](https://twitter.com/iScienceLuvr/status/1592860019057250304)
- [Implementation of Paint-with-words with Stable Diffusion](https://github.com/cloneofsimo/paint-with-words-sd)
- [Seeing Beyond the Brain: Conditional Diffusion Model with Sparse Masked Modeling for Vision Decoding (2022)](https://mind-vis.github.io/) ([Code](https://github.com/zjc062/mind-vis)) ([HN](https://news.ycombinator.com/item?id=33632337))
- [PALBERT: Teaching ALBERT to Ponder (2022)](https://arxiv.org/abs/2204.03276) ([Code](https://github.com/tinkoff-ai/palbert))
- [DiffusionDet: Diffusion Model for Object Detection (2022)](https://arxiv.org/abs/2211.09788) ([Code](https://github.com/ShoufaChen/DiffusionDet))
- [Some notes on the Stable Diffusion safety filter (2022)](https://vickiboykis.com/2022/11/18/some-notes-on-the-stable-diffusion-safety-filter/) ([HN](https://news.ycombinator.com/item?id=33656785))
- [Lightning Diffusion](https://github.com/Lightning-AI/lightning-diffusion) - Provides components to finetune and serve diffusion model on lightning.ai.
- [Deforum Stable Diffusion](https://github.com/deforum-art/deforum-stable-diffusion)
- [Deforum](https://deforum.github.io/) - Community of AI image synthesis developers, enthusiasts, and artists. ([GitHub](https://github.com/deforum-art))
- [Shift-Attention](https://github.com/yownas/shift-attention) - In stable diffusion, generate a sequence of images shifting attention in the prompt.
- [London, 1910 by Midjourney](https://www.reddit.com/r/midjourney/comments/yyom8a/london_1910/)
- [GeoDiff: a Geometric Diffusion Model for Molecular Conformation Generation (2022)](https://arxiv.org/abs/2203.02923) ([Code](https://github.com/MinkaiXu/GeoDiff))
- [Magic3D: High-Resolution Text-to-3D Content Creation (2022)](https://deepimagination.cc/Magic3D/) ([HN](https://news.ycombinator.com/item?id=33689096))
- [Stable Diffusion with Nix](https://github.com/collinarnett/stable-diffusion-nix) - Quickly get up and running using Stable Diffusion with Nix flakes.
- [Minimal text diffusion](https://github.com/madaan/minimal-text-diffusion) - Minimal implementation of diffusion models for text generation.
- [VectorFusion: Text-to-SVG by Abstracting Pixel-Based Diffusion Models (2022)](https://ajayj.com/vectorfusion)
- [RAD-NeRF: Real-time Neural Talking Portrait Synthesis](https://github.com/ashawkey/RAD-NeRF)
- [OpenAI Cookbook](https://github.com/openai/openai-cookbook) - Examples and guides for using the OpenAI API.
- [Dispict](https://github.com/ekzhang/dispict) - Design a growing artistic exhibit of your own making, with semantic search powered by OpenAI CLIP.
